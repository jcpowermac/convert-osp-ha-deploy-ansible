# This file can be used directly by 'phd', see 'build-all.sh' in this
# directory for how it can be invoked.  The only requirement is a list
# of nodes you'd like it to modify.
#
# The scope of each command-block is controlled by the preceeding
# 'target' line. 
#
# - target=all
#   The commands are executed on evey node provided
#
# - target=local
#   The commands are executed from the node hosting phd. When not
#   using phd, they should be run from some other independant host
#   (such as the puppet master)
#
# - target=$PHD_ENV_nodes{N}
#   The commands are executed on the Nth node provided.
#   For example, to run on only the first node would be target=$PHD_ENV_nodes1
#
# Tasks to be performed at this step include:

#################################
# Scenario Requirements Section #
#################################
= VARIABLES =

PHD_VAR_network_hosts_rabbitmq
PHD_VAR_osp_configdir
PHD_VAR_deployment

#################################
# Scenario Requirements Section #
#################################
= REQUIREMENTS =
nodes: 1

######################
# Deployment Scripts #
######################
= SCRIPTS =


target=all
....
yum install -y openstack-glance openstack-utils python-openstackclient

# Configure the API service

openstack-config --set /etc/glance/glance-api.conf database connection mysql://glance:glancetest@vip-db/glance
openstack-config --set /etc/glance/glance-api.conf database max_retries -1

openstack-config --set /etc/glance/glance-api.conf paste_deploy flavor keystone

openstack-config --set /etc/glance/glance-api.conf keystone_authtoken identity_uri http://vip-keystone:35357/
openstack-config --set /etc/glance/glance-api.conf keystone_authtoken auth_uri http://vip-keystone:5000/
openstack-config --set /etc/glance/glance-api.conf keystone_authtoken admin_tenant_name services
openstack-config --set /etc/glance/glance-api.conf keystone_authtoken admin_user glance
openstack-config --set /etc/glance/glance-api.conf keystone_authtoken admin_password glancetest

openstack-config --set /etc/glance/glance-api.conf DEFAULT notification_driver messaging

openstack-config --set /etc/glance/glance-api.conf oslo_messaging_rabbit rabbit_hosts ${PHD_VAR_network_hosts_rabbitmq}
openstack-config --set /etc/glance/glance-api.conf oslo_messaging_rabbit rabbit_ha_queues true

openstack-config --set /etc/glance/glance-api.conf DEFAULT registry_host vip-glance
openstack-config --set /etc/glance/glance-api.conf DEFAULT bind_host $(ip addr show dev eth1 scope global | grep dynamic| sed -e 's#.*inet ##g' -e 's#/.*##g')

# Configure the registry service

openstack-config --set /etc/glance/glance-registry.conf database connection mysql://glance:glancetest@vip-db/glance
openstack-config --set /etc/glance/glance-registry.conf database max_retries -1

openstack-config --set /etc/glance/glance-registry.conf paste_deploy flavor keystone

openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken identity_uri http://vip-keystone:35357/
openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken auth_uri http://vip-keystone:5000/
openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken admin_tenant_name services
openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken admin_user glance
openstack-config --set /etc/glance/glance-registry.conf keystone_authtoken admin_password glancetest

openstack-config --set /etc/glance/glance-registry.conf DEFAULT notification_driver messaging

openstack-config --set /etc/glance/glance-registry.conf oslo_messaging_rabbit rabbit_hosts ${PHD_VAR_network_hosts_rabbitmq}
openstack-config --set /etc/glance/glance-registry.conf oslo_messaging_rabbit rabbit_ha_queues true

openstack-config --set /etc/glance/glance-registry.conf DEFAULT registry_host vip-glance
openstack-config --set /etc/glance/glance-registry.conf DEFAULT bind_host $(ip addr show dev eth1 scope global | grep dynamic| sed -e 's#.*inet ##g' -e 's#/.*##g')

# create the NFS share mountpoint on the nfs server
mkdir -p $PHD_VAR_osp_configdir/glance
....

target=$PHD_ENV_nodes1
....
# Now have pacemaker mount the NFS share as service.
pcs resource create glance-fs Filesystem  device="${PHD_VAR_network_internal}.1:$PHD_VAR_osp_configdir/glance"   directory="/var/lib/glance"  fstype="nfs" options="v3" --clone

# wait for glance-fs to be started and running
sleep 5

# Make sure it's writable
chown glance:nobody /var/lib/glance

# Now populate the database
su glance -s /bin/sh -c "glance-manage db_sync"

pcs resource create glance-registry systemd:openstack-glance-registry --clone
pcs resource create glance-api systemd:openstack-glance-api --clone

pcs constraint order start glance-fs-clone then glance-registry-clone
pcs constraint colocation add glance-registry-clone with glance-fs-clone
pcs constraint order start glance-registry-clone then glance-api-clone
pcs constraint colocation add glance-api-clone with glance-registry-clone

if [ $PHD_VAR_deployment = collapsed ]; then
   pcs constraint order start keystone-clone then glance-registry-clone
fi
....

